---
title: Projects
layout: page
excerpt: SEA Lab - Projects
permalink: /projects/
---

<div class="container">
    <p>
        Lab research focuses on social media as a source of research questions and a source of data. No other technology has changed everyday lives as profoundly and rapidly as social media. Platforms like Twitter, Facebook, and Tiktok now connect billions of people within online spaces to exchange ideas and information, work, socialize, date, entertain themselves and even fight wars. These massive, global interconnections promote liberty, openness and the free exchange of ideas. However, due to their low barrier to entry and global reach, social platforms have become a target for social manipulation by malicious actors who aim to spread misinformation, inflame culture wars, and create polarization. My research attempts to reduce these harms and increase the benefits of interconnectedness through the synthesis of social networks and AI.
    </p>

    <h2>Collective Psychology on Social Media</h2>

    <div class="row">
        <div class="col-md-12">
            <div class="image-wrap">
                <img src="/assets/images/proj-1.jpg" alt="Project Image 1" class="img-fluid">
            </div>
            <p>
                Social media connects people at an emotional level, allowing them to share their own feelings and to react to the feelings of others at an unprecedented scale and speed. Emotional connection can be a force for good, knitting people within communities that provide a shared group identity and help make sense of a chaotic world. But, it can also erode wellbeing through negative social comparisons or by trapping people within toxic echo chambers that harm mental health. Online emotions can also amplify affective polarization by exposing people to the opinions of their ideological foes, which can rapidly entrench political divides, and allow malicious actors to manipulate beliefs at scale through coordinated influence campaigns. We are mapping collective emotional dynamics at a global scale to understand the complex interplay between emotions, identity and beliefs.
            </p>
        </div>
    </div>

    <h4>Representative publications</h4>
    <ul>
        <li>Lerman, K., Feldman, D., He, Z., & Rao, A. (2024). Affective polarization and dynamics of information spread in online networks. npj Complexity, 1(1), 8.</li>
        <li>Nettasinghe, B., Percus, A. G., & Lerman, K. (2024). Dynamics of Affective Polarization: From Consensus to Partisan Divides. arXiv preprint arXiv:2403.16940.</li>
        <li>Lerman, K., Karnati, A., Zhou, S., Chen, S., Kumar, S., He, Z., ... & Horn, A. (2023). Radicalized by Thinness: Using a Model of Radicalization to Understand Pro-Anorexia Communities on Twitter. arXiv preprint arXiv:2305.11316.</li>
        <li>Burghardt, K., Rao, A., Chochlakis, G., Sabyasachee, B., Guo, S., He, Z., ... & Lerman, K. (2024). Socio-linguistic characteristics of coordinated inauthentic accounts. In Proceedings of the International AAAI Conference on Web and Social Media (Vol. 18, pp. 164-176).</li>
    </ul>

    <div class="my-5"></div>

    <h2>Bias in Data and AI Fairness</h2>

    <div class="row">
        <div class="col-md-12">
            <div class="image-wrap">
                <img src="/assets/images/proj-1.jpg" alt="Image 2" class="img-fluid">
            </div>
            <p>
                Our reliance on data to fuel AI raises important questions about fairness and ethics. Social data is often heterogeneous, as it comes from a population composed of subgroups with different characteristics and behaviors. A trend in aggregate data may disappear or reverse when the data is disaggregated into its constituent subgroups. This effect, known as Simpson's paradox, often confounds models learned from data. We are developing methods to quantify biases in heterogeneous data. One approach leverages the Simpson's paradox by accounting for latent groups to learn more robust and generalizable models. We are also developing principled mathematical methods to create unbiased features for learning fair models, or use affirmative action to improve collective outcomes of interventions.
            </p>
        </div>
    </div>

    <h4>Representative publications</h4>
    <ul>
        <li>Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A survey on bias and fairness in machine learning. ACM computing surveys (CSUR), 54(6), 1-35.</li>
        <li>Lerman, K. (2018). Computational social scientist beware: Simpson's paradox in behavioral data. Journal of Computational Social Science, 1(1), 49-58.</li>
        <li>He, Y., Burghardt, K., & Lerman, K. (2020, February). A geometric solution to fair representations. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (pp. 279-285).</li>
    </ul>
</div>
